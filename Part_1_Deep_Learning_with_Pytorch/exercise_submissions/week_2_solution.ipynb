{"cells":[{"cell_type":"markdown","metadata":{"id":"2zCJo9VlnNLH"},"source":["## Arewa Data Science Academy\n","### Deep Learning Cohort1.0\n","\n","#### Name: Ibrahim Ismaila\n","#### Email: ibrahim5322022@hotmail.com\n","#### Title: Week 2 Solution"]},{"cell_type":"markdown","metadata":{"id":"c2WPhl-onNLN"},"source":["### Exercises Solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FN9bTAIjnNLO"},"outputs":[],"source":["# Exercise 1a- Solution\n","a = torch.tensor([1, 2])"]},{"cell_type":"code","source":["Create a straight line dataset using the linear regression formula (weight * X + bias).\n","Set weight=0.3 and bias=0.9 there should be at least 100 datapoints total.\n","Split the data into 80% training, 20% testing.\n","Plot the training and testing data so it becomes visual.\n","\n","\n","\n","\n","\n","\n","Build a PyTorch model by subclassing nn.Module.\n","Inside should be a randomly initialized nn.Parameter() with requires_grad=True, one for weights and one for bias.\n","Implement the forward() method to compute the linear regression function you used to create the dataset in 1.\n","Once you've constructed the model, make an instance of it and check its state_dict().\n","Note: If you'd like to use nn.Linear() instead of nn.Parameter() you can.\n","\n","\n","Create a loss function and optimizer using nn.L1Loss() and torch.optim.SGD(params, lr) respectively.\n","Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters from the model you created in 2.\n","\n","\n","\n","Write a training loop to perform the appropriate training steps for 300 epochs.\n","The training loop should test the model on the test dataset every 20 epochs.\n","\n","Make predictions with the trained model on the test data.\n","Visualize these predictions against the original training and testing data (note: you may need to make sure the predictions are not on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot).\n","\n","\n","Save your trained model's state_dict() to file.\n","Create a new instance of your model class you made in 2. and load in the state_dict() you just saved to it.\n","Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."],"metadata":{"id":"BYHXCoB6nyab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Linear Regression with PyTorch\n"],"metadata":{"id":"_0mVOBiWnyYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create a Straight Line Dataset\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from sklearn.model_selection import train_test_split\n","\n","# Create dataset\n","weight = 0.3\n","bias = 0.9\n","X = np.linspace(0, 1, 100)\n","y = weight * X + bias + np.random.randn(*X.shape) * 0.05  # Adding some noise\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Plot the dataset\n","plt.scatter(X_train, y_train, label=\"Training data\")\n","plt.scatter(X_test, y_test, label=\"Testing data\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"IYEkoUI8nyV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build a PyTorch Model\n","import torch.nn as nn\n","\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self):\n","        super(LinearRegressionModel, self).__init__()\n","        self.weight = nn.Parameter(torch.randn(1), requires_grad=True)\n","        self.bias = nn.Parameter(torch.randn(1), requires_grad=True)\n","\n","    def forward(self, x):\n","        return self.weight * x + self.bias\n","\n","# Instantiate the model\n","model = LinearRegressionModel()\n","print(model.state_dict())\n"],"metadata":{"id":"3UuLOOBknyRd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a Loss Function and Optimizer\n","loss_fn = nn.L1Loss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"],"metadata":{"id":"vvF8g7YRnyPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","# Convert data to tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n","\n","# Training loop\n","epochs = 300\n","for epoch in range(epochs):\n","    model.train()\n","\n","    # Forward pass\n","    y_pred = model(X_train_tensor)\n","    loss = loss_fn(y_pred, y_train_tensor)\n","\n","    # Backward pass\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Test model every 20 epochs\n","    if (epoch + 1) % 20 == 0:\n","        model.eval()\n","        with torch.no_grad():\n","            test_pred = model(X_test_tensor)\n","            test_loss = loss_fn(test_pred, y_test_tensor)\n","            print(f\"Epoch {epoch+1}, Train Loss: {loss.item()}, Test Loss: {test_loss.item()}\")"],"metadata":{"id":"Mi72bHosnyNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make Predictions and Visualize\n","# Make predictions\n","model.eval()\n","with torch.no_grad():\n","    predictions = model(X_test_tensor)\n","\n","# Plot predictions\n","plt.scatter(X_train, y_train, label=\"Training data\")\n","plt.scatter(X_test, y_test, label=\"Testing data\")\n","plt.scatter(X_test, predictions.numpy(), label=\"Predictions\", marker='x')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"8EIpsyU7nyLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save and Load Model\n","# Save the model state_dict\n","torch.save(model.state_dict(), \"linear_model.pth\")\n","\n","# Load the model\n","new_model = LinearRegressionModel()\n","new_model.load_state_dict(torch.load(\"linear_model.pth\"))\n","new_model.eval()\n","\n","# Confirm predictions match\n","with torch.no_grad():\n","    new_predictions = new_model(X_test_tensor)\n","    assert torch.allclose(predictions, new_predictions)\n","    print(\"Loaded model predictions match original model predictions.\")"],"metadata":{"id":"pHwZKXE9nyIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Synchronous Machine Learning Dataset"],"metadata":{"id":"F-Zky3K6nyGJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKvfEaELnNLR"},"outputs":[],"source":["# Load and Convert Data\n","import zipfile\n","import pandas as pd\n","import torch\n","\n","# Download dataset in colab env\n","!wget https://archive.ics.uci.edu/static/public/607/synchronous+machine+data+set.zip -O data.zip\n","\n","# Unzip data\n","with zipfile.ZipFile(\"data.zip\", 'r') as my_zip:\n","    my_zip.extractall()\n","\n","# Read CSV and parse to pandas\n","dataset_name = \"synchronous machine.csv\"\n","data = pd.read_csv(dataset_name, delimiter=\";\", thousands=',')\n","numpy_data = data.values\n","\n","# Convert to PyTorch tensor\n","original_data_tensor = torch.tensor(numpy_data, dtype=torch.float32)\n"]},{"cell_type":"code","source":["# Tensor Manipulation\n","# (a) Print size\n","print(\"Size of dataset:\", original_data_tensor.size())\n","\n","# (b) Create my_pi_tensor\n","my_pi_tensor = torch.full_like(original_data_tensor, 3.142, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","print(\"First 13 rows of my_pi_tensor:\", my_pi_tensor[:13])\n","print(\"Tensor device:\", my_pi_tensor.device)\n","print(\"Tensor datatype:\", my_pi_tensor.dtype)\n","\n","# (c) Fifth-root of the sum of all values in my_pi_tensor\n","fifth_root = torch.sum(my_pi_tensor).pow(1/5)\n","print(\"Fifth-root of the sum:\", fifth_root)\n","\n","# (d) Create my_data_tensor\n","my_data_tensor = torch.cat((original_data_tensor[:100], original_data_tensor[-100:]), dim=0)\n","print(\"Size of my_data_tensor:\", my_data_tensor.size())\n","\n","# (e) Create features and target tensors\n","features = my_data_tensor[:, 0]  # dIf column\n","target = my_data_tensor[:, 1]    # If column\n","\n","# (f) Split data into training and testing sets\n","train_size = int(0.75 * len(my_data_tensor))\n","train_features, test_features = features[:train_size], features[train_size:]\n","train_target, test_target = target[:train_size], target[train_size:]"],"metadata":{"id":"PqXnHjD0qMdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Linear Model\n","class SynchronousMachineLinearModel(nn.Module):\n","    def __init__(self):\n","        super(SynchronousMachineLinearModel, self).__init__()\n","        self.linear = nn.Linear(1, 1)\n","\n","    def forward(self, x):\n","        return self.linear(x)"],"metadata":{"id":"fFqie6XTqMbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train Model\n","# Initialize the model\n","model = SynchronousMachineLinearModel()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","loss_fn = nn.MSELoss()\n","\n","# Training loop\n","epochs = 100\n","train_losses, test_losses = [], []\n","\n","for epoch in range(epochs):\n","    model.train()\n","\n","    # Forward pass\n","    y_pred = model(train_features.unsqueeze(1))\n","    train_loss = loss_fn(y_pred, train_target.unsqueeze(1))\n","\n","    # Backward pass\n","    optimizer.zero_grad()\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # Evaluate on test set\n","    model.eval()\n","    with torch.no_grad():\n","        test_pred = model(test_features.unsqueeze(1))\n","        test_loss = loss_fn(test_pred, test_target.unsqueeze(1))\n","\n","    train_losses.append(train_loss.item())\n","    test_losses.append(test_loss.item())\n","\n","    print(f\"Epoch {epoch+1}, Train Loss: {train_loss.item()}, Test Loss: {test_loss.item()}\")\n","\n","# Plot Loss against Epoch\n","plt.plot(range(epochs), train_losses, label=\"Train Loss\")\n","plt.plot(range(epochs), test_losses, label=\"Test Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"4-0emownqMZl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Comment on Results\n","\n","The model's performance can be improved by tuning hyperparameters such as the learning rate, increasing the number of epochs, or using a more complex model architecture. Feature engineering and data preprocessing might also contribute to better predictions.\n","\n","With this guide, you should be able to train multiple models using PyTorch, track them with MLflow, and deploy the best one on Streamlit. Feel free to explore further and customize the code as needed! If you have any questions or need additional assistance, let me know.\n"],"metadata":{"id":"HfeNKPjoqMXi"}},{"cell_type":"code","source":[],"metadata":{"id":"V-JlkghAqMQ1"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"13LRM1RPeeCnq_IKQxAY0SxfK1Dnar-bt","timestamp":1738247345000}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}